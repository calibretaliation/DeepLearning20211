{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_net_tf.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calibretaliation/DeepLearning20211/blob/main/siamese_net_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NijPZmQCTMkj",
        "outputId": "6791bae5-af57-4f0d-b7c8-ae9bc241e383"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "istTBFbsNPcR",
        "outputId": "e609afe2-eb2d-47db-94e8-7f71093a3720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepLearning20211'...\n",
            "remote: Enumerating objects: 32685, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (219/219), done.\u001b[K\n",
            "remote: Total 32685 (delta 130), reused 0 (delta 0), pack-reused 32466\u001b[K\n",
            "Receiving objects: 100% (32685/32685), 1.68 GiB | 28.93 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "Checking out files: 100% (32430/32430), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/calibretaliation/DeepLearning20211.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "CeDeB7H-A5Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "id": "cUOIsVncQGib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10313ce-a93f-49fa-d752-119574e51554"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-3v62_4c1\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-3v62_4c1\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (2.11.3)\n",
            "Requirement already satisfied: protobuf>=3.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.13)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.14->tensorflow-docs==0.0.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.0.1)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=162411 sha256=96a3428e9fb58b590c10e8686b6e6f2f524a5b355febc0fdcbc7b53524d6f314\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b30f4nl8/wheels/cc/c4/d8/5341e93b6376c5c929c49469fce21155eb69cef1a4da4ce32c\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: tensorflow-docs\n",
            "Successfully installed tensorflow-docs-0.0.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import math\n",
        "import random\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import applications, layers, losses, optimizers, metrics, Model, callbacks\n",
        "from tensorflow.keras.applications import resnet, mobilenet_v3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow_docs.plots\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "WJyjcOIXQTWO",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load CSV\n",
        "\n",
        "train_df = pd.read_csv('DeepLearning20211/data/train.csv')\n",
        "test_df = pd.read_csv('DeepLearning20211/data/test.csv')\n",
        "\n",
        "train_img_dir = Path('DeepLearning20211/data/train_images')\n",
        "test_img_dir = Path('DeepLearning20211/data/test_images/')\n",
        "\n",
        "# Drop images with duplicated p-hash value \n",
        "train_df = train_df.drop_duplicates(subset=['image_phash']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "0NZlAgwOQj9q",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot class cardinality distribution\n",
        "\n",
        "# calculate number of images in each class\n",
        "label_count = train_df['label_group'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "label_count.value_counts().plot.bar()\n",
        "plt.xlabel('Class cardinality')\n",
        "plt.ylabel('Number of class')\n",
        "plt.title('Shopee Class cardinality distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "cellView": "form",
        "id": "w8c7i4HsoEeI",
        "outputId": "f0155f54-9fed-48d3-d82c-8149b684a9d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset"
      ],
      "metadata": {
        "id": "G2uFtS8S6kM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Take one instance in each class as anchor\n",
        "\n",
        "set_seed(42)\n",
        "anchor_df = train_df.groupby('label_group').nth(0)"
      ],
      "metadata": {
        "id": "RMaBhhzUvzcA",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create validation set\n",
        "val_df = train_df.sample(frac=1, random_state=14).groupby('label_group').nth(0)\n",
        "val_df['label_group'] = val_df.index\n",
        "val_df = val_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "A8qZubQ5YHRv",
        "cellView": "form"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# shutil.rmtree(str(temp_dir), ignore_errors=True)"
      ],
      "metadata": {
        "id": "zkU51fPtt8h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup model"
      ],
      "metadata": {
        "id": "KILeLz9iOWAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define embedding model (Run only once)\n",
        "base_model = tf.keras.applications.MobileNetV3Large(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\n",
        "\n",
        "output = layers.Flatten()(base_model.output)\n",
        "output = layers.Dense(512, activation='relu')(output)\n",
        "output = layers.BatchNormalization()(output)\n",
        "output = layers.Dense(256, activation='relu')(output)\n",
        "output = layers.BatchNormalization()(output)\n",
        "output = layers.Dense(256, activation='relu')(output)\n",
        "output = layers.BatchNormalization()(output)\n",
        "\n",
        "embedding = Model(base_model.input, output, name='Embedding')\n"
      ],
      "metadata": {
        "id": "JeaSzkDi_x-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.summary()"
      ],
      "metadata": {
        "id": "PGkdwkjF_B5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose layer to freeze\n",
        "\n",
        "layer_name = 'multiply_61' #@param {type: 'string'}\n",
        "\n",
        "trainable = False\n",
        "for layer in base_model.layers:\n",
        "    if layer.name == layer_name:\n",
        "        trainable = True\n",
        "    layer.trainable = trainable\n",
        "\n",
        "class Distance(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, anchor, positive, negative):\n",
        "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
        "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
        "        return ap_distance, an_distance\n",
        "\n",
        "anchor_input = layers.Input(name='anchor', shape=(224, 224, 3))\n",
        "positive_input = layers.Input(name='positive', shape=(224, 224, 3))\n",
        "negative_input = layers.Input(name='negative', shape=(224, 224, 3))\n",
        "\n",
        "distances = Distance()(\n",
        "    embedding(mobilenet_v3.preprocess_input(anchor_input)),\n",
        "    embedding(mobilenet_v3.preprocess_input(positive_input)),\n",
        "    embedding(mobilenet_v3.preprocess_input(negative_input))\n",
        ")\n",
        "\n",
        "siamese_base = Model(\n",
        "    inputs=[anchor_input, positive_input, negative_input],\n",
        "    outputs=distances\n",
        ")\n",
        "\n",
        "class SiameseNet(Model):\n",
        "    \"\"\"\n",
        "    Siamese network with triplet loss:\n",
        "        L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
        "    \"\"\"\n",
        "    def __init__(self, siamese_base, margin=0.5):\n",
        "        super(SiameseNet, self).__init__()\n",
        "        self.siamese_base = siamese_base\n",
        "        self.margin = margin\n",
        "        self.loss_tracker = metrics.Mean(name='loss')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.siamese_base(inputs)\n",
        "\n",
        "    @tf.function\n",
        "    def _compute_loss(self, data):\n",
        "        ap_distance, an_distance = self.siamese_base(data)\n",
        "        loss = tf.maximum(ap_distance + self.margin - an_distance, 0.0)\n",
        "        return loss\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self._compute_loss(data)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.siamese_base.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.siamese_base.trainable_weights))\n",
        "        \n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {'loss': self.loss_tracker.result()}\n",
        "\n",
        "    @tf.function\n",
        "    def test_step(self, data):\n",
        "        loss = self._compute_loss(data)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {'val_loss': self.loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # list our metrics here so the `reset_states()` can be called automatically.\n",
        "        return [self.loss_tracker]\n",
        "\n"
      ],
      "metadata": {
        "id": "jTYtsebDM1cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveModelOnBatch(callbacks.Callback):\n",
        "    def __init__(self, n, path, terminate_batch=None):\n",
        "        super(SaveModelOnBatch, self).__init__()\n",
        "        self.n = n\n",
        "        self.path = path\n",
        "        self.terminate_batch = terminate_batch\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        if batch > 0 and batch % self.n == 0:\n",
        "            print('Current loss:', logs.get('loss'))\n",
        "            embedding.save(self.path + os.sep + 'embedding')\n",
        "            print('embedding saved at', self.path + os.sep + 'embedding')\n",
        "            # siamese_base.save(self.path + os.sep + 'siamese_base')\n",
        "            # print('siamese_base saved at', self.path + os.sep + 'siamese_base')\n",
        "        if batch == self.terminate_batch:\n",
        "            self.model.stop_training = True\n",
        "            return"
      ],
      "metadata": {
        "id": "Jk41Y7bC3-ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SiameseNet(siamese_base, 1.0)\n",
        "model.compile(optimizer=SGD(learning_rate=1e-5, momentum=0.9, nesterov=True))\n",
        "history = model.fit(train_ds, \n",
        "          epochs=2, \n",
        "          validation_data=val_ds, \n",
        "          shuffle=True, \n",
        "          callbacks=[SaveModelOnBatch(200, '/content/drive/MyDrive/checkpoint'),\n",
        "                    #  callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.1, patience=1, verbose=1),\n",
        "                    #  callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, restore_best_weights=True)\n",
        "                     ]\n",
        ")"
      ],
      "metadata": {
        "id": "XF3xflRKG4CD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5053e31d-0723-4668-f497-36c6551f15c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "  200/34388 [..............................] - ETA: 68:10:51 - loss: 0.9034Current loss: 0.9027803540229797\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            "  400/34388 [..............................] - ETA: 69:30:45 - loss: 0.8640Current loss: 0.8638365268707275\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            "  600/34388 [..............................] - ETA: 70:01:35 - loss: 0.8315Current loss: 0.8313974738121033\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            "  800/34388 [..............................] - ETA: 69:50:16 - loss: 0.8076Current loss: 0.8075528144836426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            " 1000/34388 [..............................] - ETA: 69:42:29 - loss: 0.7893Current loss: 0.7893808484077454\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            " 1200/34388 [>.............................] - ETA: 69:29:54 - loss: 0.7693Current loss: 0.7691348791122437\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            " 1400/34388 [>.............................] - ETA: 69:13:29 - loss: 0.7498Current loss: 0.7497460842132568\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            " 1600/34388 [>.............................] - ETA: 68:56:01 - loss: 0.7347Current loss: 0.7345338463783264\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            " 1800/34388 [>.............................] - ETA: 68:40:12 - loss: 0.7186Current loss: 0.7184807062149048\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            " 2000/34388 [>.............................] - ETA: 68:18:45 - loss: 0.7041Current loss: 0.7040671706199646\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/embedding/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding saved at /content/drive/MyDrive/checkpoint/embedding\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/checkpoint/siamese_base/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siamese_base saved at /content/drive/MyDrive/checkpoint/siamese_base\n",
            " 2088/34388 [>.............................] - ETA: 68:27:57 - loss: 0.6989"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch = 64 hội tụ nhanh hơn 32"
      ],
      "metadata": {
        "id": "Xr1_2jIbeGGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.save('/content/drive/MyDrive/checkpoint/embedding')"
      ],
      "metadata": {
        "id": "7HSTerm2enAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = tf.keras.models.load_model('/content/drive/MyDrive/checkpoint/embedding_0')"
      ],
      "metadata": {
        "id": "RnKZxXrdiyPM",
        "outputId": "a7912a6b-ec49-443d-965d-b10d909566a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "anchor_paths = (str(train_img_dir) + os.sep + anchor_df['image']).to_list()\n",
        "anchor_label_group = anchor_df.index.to_list()\n",
        "\n",
        "anchor_embedding = embedding.predict(\n",
        "    mobilenet_v3.preprocess_input(\n",
        "        tf.data.Dataset.from_tensor_slices(anchor_paths).map(\n",
        "            filepath_to_img, num_parallel_calls=tf.data.AUTOTUNE\n",
        "            ).prefetch(buffer_size=512).batch(32)\n",
        "    )\n",
        ")\n",
        "\n",
        "# anchor_embedding = tf.data.Dataset.from_tensor_slices(anchor_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbw5RPehrFyD",
        "outputId": "7a8a7d60-cb64-42d0-d4bb-f952a1084ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min, sys: 6.68 s, total: 2min 6s\n",
            "Wall time: 1min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "\n",
        "label_group_to_anchor_index = np.vectorize(lambda label_group: anchor_label_group.index(label_group))\n",
        "\n",
        "val_predictions = tf.data.Dataset.from_tensor_slices(str(train_img_dir) + os.sep +  val_df['image'])\n",
        "\n",
        "val_predictions = val_predictions.map(lambda filepath: tf.squeeze(embedding(tf.expand_dims(mobilenet_v3.preprocess_input(data_augmentation(filepath_to_img(filepath))), axis=0))))\n",
        "val_predictions = val_predictions.prefetch(buffer_size=11004)\n",
        "\n",
        "val_predictions = val_predictions.map(lambda embedding_vector: tf.map_fn(lambda x: 1/tf.reduce_sum(tf.square(x - embedding_vector)), anchor_embedding))"
      ],
      "metadata": {
        "id": "WNxEPI4KL3FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = label_group_to_anchor_index(val_df['label_group'])\n",
        "pred = [p for p in val_predictions]"
      ],
      "metadata": {
        "id": "rLKL9Dv9eZS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy = metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for l, p in zip(label, pred):\n",
        "    val_accuracy.update_state(l, p)  \n",
        "\n",
        "val_accuracy.result()  "
      ],
      "metadata": {
        "id": "stJ8SssO39u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hmmm"
      ],
      "metadata": {
        "id": "P9ucn984SDkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-FUn68TYldh",
        "outputId": "155abc1b-23c1-4156-e45f-03cba7e12bfe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "import seaborn as sns\n",
        "from matplotlib import cm"
      ],
      "metadata": {
        "id": "Nd70z2wqY0xC"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_df['label_group'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK6tAinAn2YQ",
        "outputId": "2bb90f27-0783-47ff-e767-3dcecb368ee6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.RandomRotation(0.5),\n",
        "     tf.keras.layers.RandomContrast(0.5),\n",
        "     tf.keras.layers.RandomZoom((-0.2, 0.2)),\n",
        "     tf.keras.layers.RandomTranslation(0.14, 0.14),\n",
        "     ]\n",
        ")\n",
        "\n",
        "def filepath_to_img(filepath):\n",
        "    \n",
        "    img_string = tf.io.read_file(filepath)\n",
        "    img = tf.image.decode_jpeg(img_string)\n",
        "\n",
        "    # img = tf.image.convert_image_dtype(img, tf.float32) # to [0, 1]\n",
        "    # img = tf.image.resize(img, (224, 224)) \n",
        "\n",
        "    return img\n",
        "\n",
        "def configure_dataset(ds, mode, fine_tune=False):\n",
        "    assert mode == 'training' or mode == 'validation', \"mode should be 'training' or 'validation'\" \n",
        "    \n",
        "    ds = ds.map(lambda filepath, label: (filepath_to_img(filepath), label), \n",
        "                num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    ds = ds.map(lambda img, label: (tf.keras.layers.Resizing(224, 224, crop_to_aspect_ratio=True)(img), label),\n",
        "                num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if not fine_tune:               #######################################\n",
        "        ds = ds.map(lambda img, label: (tf.keras.layers.Rescaling(1./255, offset=-1)(img), label),\n",
        "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # if mode == 'training':\n",
        "    ds = ds.map(lambda img, label: (data_augmentation(img), label), \n",
        "                num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    ds = ds.prefetch(buffer_size=2048)\n",
        "    \n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "    return ds"
      ],
      "metadata": {
        "id": "pAnPUmVTSG6M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ncols = 3\n",
        "nrows = 3\n",
        "plt.figure(figsize=(4*ncols, 4*nrows))\n",
        "spec = gridspec.GridSpec(ncols=ncols, nrows=nrows)\n",
        "for img_batch, label_batch in train_ds.take(1):\n",
        "    i = 0\n",
        "    for img, label in zip(img_batch, label_batch):\n",
        "        plt.subplot(spec[i])\n",
        "        plt.imshow(img)\n",
        "        plt.title(label.numpy())\n",
        "        plt.axis('off')\n",
        "\n",
        "        i += 1\n",
        "        if i == nrows * ncols:\n",
        "            break\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cetzlq5IUJ0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define embedding model (Run only once)\n",
        "base_model = tf.keras.applications.MobileNetV3Large(weights='imagenet', input_shape=(224, 224, 3), include_top=False, include_preprocessing=True)\n",
        "\n",
        "output = layers.Flatten()(base_model.output)\n",
        "output = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(output)\n",
        "\n",
        "embedding = Model(base_model.input, output, name='Embedding')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWdGJUGlXDqr",
        "outputId": "3f3a225a-cc48-4aac-a501-d5ae3664994e",
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top.h5\n",
            "17612800/17605208 [==============================] - 0s 0us/step\n",
            "17620992/17605208 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.summary()"
      ],
      "metadata": {
        "id": "caQmh6jjXDq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose layer to freeze\n",
        "\n",
        "layer_name = 'multiply_14' #@param {type: 'string'}\n",
        "\n",
        "trainable = False\n",
        "for layer in base_model.layers:\n",
        "    if layer.name == layer_name:\n",
        "        trainable = True\n",
        "    layer.trainable = trainable\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Llx4c4YJXDq5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = pd.concat([val_df, val_df]).sort_index(axis=0)\n",
        "val_labels = label_encoder.transform(val_ds['label_group'])\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((str(train_img_dir) + os.sep + val_ds['image'], val_labels))\n",
        "val_ds = configure_dataset(val_ds, mode='validation', fine_tune=True)   # evaluation using keras pretrained-model"
      ],
      "metadata": {
        "id": "1X9BQITyClpS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_histories = []"
      ],
      "metadata": {
        "id": "zmY_9JIHffLy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.compile(\n",
        "    optimizer=SGD(learning_rate=5e-3, momentum=0.9, nesterov=True),\n",
        "    loss=tfa.losses.TripletSemiHardLoss(),\n",
        "    )\n",
        "\n",
        "max_epoch = 3\n",
        "for epoch in range(max_epoch):\n",
        "    train_df = train_df.sample(frac=1.0).reset_index(drop=True)\n",
        "    train_ds = pd.concat([train_df, train_df]).sort_index(axis=0)\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((str(train_img_dir) + os.sep + train_ds['image'], label_encoder.transform(train_ds['label_group'])))\n",
        "    train_ds = configure_dataset(train_ds, mode='training', fine_tune=True)     # training using keras pretrained-model\n",
        "\n",
        "    print('Epoch %d/%d' % (epoch + 1, max_epoch))\n",
        "\n",
        "    epoch_histories.append(embedding.fit(\n",
        "                                        train_ds,\n",
        "                                        epochs=1,\n",
        "                                        validation_data=val_ds)\n",
        "    )"
      ],
      "metadata": {
        "id": "hwstKXvA74X1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ab5be6-d001-405c-8b43-7b2fb20fccc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "898/898 [==============================] - 1282s 1s/step - loss: 0.4913 - val_loss: 0.4071\n",
            "Epoch 2/3\n",
            "898/898 [==============================] - 1254s 1s/step - loss: 0.3453 - val_loss: 0.3313\n",
            "Epoch 3/3\n",
            "898/898 [==============================] - 1286s 1s/step - loss: 0.2952 - val_loss: 0.2930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anchor_ds = pd.concat([train_df for _ in range(4)]).sort_index(axis=0)\n",
        "anchor_labels = label_encoder.transform(anchor_ds['label_group'])\n",
        "anchor_ds = tf.data.Dataset.from_tensor_slices((str(train_img_dir) + os.sep + anchor_ds['image'], anchor_labels))\n",
        "anchor_ds = configure_dataset(anchor_ds, mode='training', fine_tune=True)\n",
        "anchor_embeddings = embedding.predict(anchor_ds)"
      ],
      "metadata": {
        "id": "9OJ5ljc_u8J9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/checkpoint/anchor_embeddings.pkl', 'wb') as f:\n",
        "    pickle.dump(anchor_embeddings, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/checkpoint/anchor_labels.pkl', 'wb') as f:\n",
        "    pickle.dump(anchor_labels, f)"
      ],
      "metadata": {
        "id": "g9Pc8NUmKZC5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors=4)\n",
        "KNN.fit(anchor_embeddings, anchor_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnhuWTCbvFCW",
        "outputId": "1afb2231-3e84-4ab7-a2fd-6d8172aec127"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=4)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_embeddings = embedding.predict(val_ds)"
      ],
      "metadata": {
        "id": "Z5JU3lRP6-7S"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_preds = KNN.predict_proba(val_embeddings)"
      ],
      "metadata": {
        "id": "RlJXJ2Z97sis"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_accuracy_score(val_labels, val_preds, k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61IrN1Af8P42",
        "outputId": "2bb79bff-8335-403a-931a-6d1d3c95499a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9908215194474737"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "decomposed_embeddings = pca.fit_transform(anchor_embeddings)"
      ],
      "metadata": {
        "id": "R1DvhAwuioJV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "sns.scatterplot(x=decomposed_embeddings[:100, 0], \n",
        "                y=decomposed_embeddings[:100, 1], \n",
        "                hue=anchor_labels[:100], \n",
        "                palette=cm.get_cmap('Spectral')\n",
        ")"
      ],
      "metadata": {
        "id": "5H9Ka-6UERG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d6a2db7e-53f6-4030-dac4-7c68a01aa604"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff850d4b9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.save('/content/drive/MyDrive/checkpoint/embedding')"
      ],
      "metadata": {
        "id": "d3OCL7R_TvO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = tf.keras.models.load_model('/content/drive/MyDrive/checkpoint/embedding')"
      ],
      "metadata": {
        "id": "J7Lf-h0GW8Df"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}